---
title: "Toyota Corolla Prediction"
output:
  word_document: default
  pdf_document: default
  html_document: default
---
```{r packages,warning=FALSE,message=FALSE,echo=FALSE}
library(ggplot2)
library(readr)
library(dplyr)
library(ggfortify)
library(patchwork)
library(corrplot)
p_theme <- theme(panel.background = element_blank(),
                 panel.grid.major.y = element_line(colour = "grey"),
                 plot.title = element_text(hjust = 0.5))
```


```{r}
data = read.csv("toyota.csv")
head(data)

#change data type
str(data)
data$FuelType = factor(data$FuelType) 
data$MetColor = factor(data$MetColor) 
data$Automatic = factor(data$Automatic) 

#check the data quality
summary(data) # found out the minimum of age is 1, which is not reasonable. KM's minimum is also 1, not reasonable, either.
sort(data$Age) #there are nearly 40 observations' age are under 16, which is not the legal age for people to drive in US
data = subset(data, data$Age>15) #remove the rows which age are under 16
sort(data$KM) # there are two observations which the KM are 1, remove them
data = subset(data, data$KM>1) #remove the abnormal data
```


```{r,echo=FALSE}
#before look at model, we can firstly get a sense of data. 
head(data)
data_FuelType = data %>% group_by(FuelType) %>% summarise(avg_price = mean(Price))
data_FuelType
ggplot(data_FuelType,aes(FuelType,avg_price,colour = FuelType,shape = FuelType)) +
  geom_point(size = 3)+
  ylim(0,13000) +
  theme_bw() + 
  ggtitle("Average Price of Different FuelType") +
  theme(plot.title = element_text(hjust = 0.5))
  
# it seems like the average price for CNG has lower than Diesel and Petrol

data_HP = data %>% group_by(HP) %>% summarise(avg_price = mean(Price))
data_HP
plot(data_HP$HP, data_HP$avg_price, type = "b", col = "Lightblue", lwd = 3, pch = 10, main = "Average Price of Different HoursePower")# it seems like the average price varies a lot with different HP

data_age = data %>% group_by(Age) %>% summarise(avg_price = mean(Price))
data_age
plot(data_age$Age, data_age$avg_price, type = "s", col = "Lightblue",lwd = 3, pch = 10, main = "Average Price of Different Age")# it seems like the price changes with different ages. the peak of the price are around 30. the price decreases as age gets older.

```

```{r,echo=FALSE,fig.align='center',fig.cap="Figure1 Correlation between prices and explanatory variables"}
head(data)
cor_df <- data[,c(1:3,5,8:10)] #correlation plot can only deal with integer variables. So, we remove the factor variables, such as FuelType, MetColor, and Automatic
cor_mm <- cor(cor_df)
cor_sig <- cor.mtest(cor_mm)
corrplot(corr = cor_mm,method = "ellipse",p.mat = cor_sig$p,insig = "label_sig")
#not only can we see the correlation between Price and other variables in the correlation matrix, but also we can see how input variables are correlated with each other. We can think about interaction between then when we are doing the linear regression model
```


```{r,fig.align='center',fig.height=2,fig.width=4}
#We did the correlation matrix of the integer variables. But there are factor variables left. So, we do the box plot to do the analysis. 
p1 <- ggplot(data,aes(Automatic,Price))+
  geom_boxplot(width=0.2,notch = T,fill = c("#CD1076","#32CD32"))+
  geom_violin(alpha=0.2,fill="#76EE00")+
  p_theme

p2 <- ggplot(data,aes(FuelType,Price))+
  geom_boxplot(width=0.2,notch = T,fill = c("#CD1076","#CDCD00","#32CD32"))+
  geom_violin(alpha=0.2,fill="#76EE00")+
  p_theme

p3 <-ggplot(data,aes(MetColor,Price))+
  geom_boxplot(width=0.2,notch = T,fill = c("#CD1076","#32CD32"))+
  geom_violin(alpha=0.2,fill="#76EE00")+
  p_theme

p1+p2+p3

ggplot(data,aes(x=Price))+geom_histogram(aes(y=..density..),bins = 100,fill="#43CD80",alpha=0.5)+
  stat_function(fun = dnorm,args = list(mean=mean(data$Price),sd=sd(data$Price)))+
  p_theme+labs(x="Residulas")

```



```{r}
#start from simple linear regression, we split the data into training and testing data set.
lm1 = lm(Price ~ ., data = data)
summary(lm1)
```

```{r}
#remove the insignificant variables
lm2 = lm(Price ~ . - Doors- MetColor, data = data) 
summary(lm2)
```


```{r}
#The model's r^2 is 83.69%. We have removed 2 insignificant variables. We would like to use stepwise to see if the chosen variables are correct.
library(leaps)
regfit.full = regsubsets(Price ~., data=data, nvmax = 9)
plot(regfit.full, scale = "adjr2",main = "Best Variables Selection Based on R^2") 
plot(regfit.full, scale = "bic",main = "Best Variables Selection Based on BIC") 
#seems like the variables selected from stepwise are the same as the variables selected from the linear model, we can use forward and backward method to varify the result
```
```{r}
regfit.fwd = regsubsets(Price ~., data=data, nvmax = 9, method = "forward")
plot(regfit.fwd, scale = "adjr2",main = "Best Variables Selection Based on R^2") 
plot(regfit.fwd, scale = "bic",main = "Best Variables Selection Based on BIC") 

regfit.bwd = regsubsets(Price ~., data=data, nvmax = 9, method = "backward")
plot(regfit.bwd, scale = "adjr2",main = "Best Variables Selection Based on R^2") 
plot(regfit.bwd, scale = "bic",main = "Best Variables Selection Based on BIC") 

#the result from backward and forward methods are the same. So, we can see if adding some interaction between variables can improve the model
```




```{r}
#after set up the linear model, we can use QQ plot and residual distribution to see if the data fits the model well. it can be seen from the plot that the data fits the model pretty well. but there are still some outliers that we need to deal with. 
summary(lm2)
autoplot(lm2)+p_theme

residual_2 <- lm2$residuals
ggplot(data = data_frame(residual_2),aes(x=residual_2))+geom_histogram(aes(y=..density..),bins = 100,fill="#43CD80",alpha=0.5)+
  stat_function(fun = dnorm,args = list(mean=mean(residual_2),sd=sd(residual_2)))+
  p_theme+labs(x="Residulas")
```



```{r}
#according to the correlation matrix, we pick some of the variables that their correlation coefficients are large
lm3=lm(Price~.-Doors-MetColor + Age:Weight + KM:HP + CC:Weight +Age:KM +Weight:Doors + I(Age^2) + I(KM^2) + I(HP^2) + I(CC^2) + I(Weight^2) + I(Doors^2) ,data = data)
summary(lm3) 

#remove insignificant variables
lm4=lm(Price~.-Automatic-Doors-MetColor + Age:Weight +Age:KM +Weight:Doors + I(KM^2) + I(HP^2) + I(CC^2) + I(Weight^2) + I(Doors^2) ,data = data)
summary(lm4) 
```


```{r}
library(tree)
data_train = sample(1:nrow(data), nrow(data)/2) # split into to equal subsets
tree.price = tree(Price~., data=data, subset=data_train)
summary(tree.price)
plot(tree.price)
text(tree.price)

data_test= data$Price[-data_train]

yhat = predict(tree.price, newdata=data[-data_train,])

sqrt(mean((yhat - data_test)^2))
```
```{r}
prune.data = prune.tree(tree.price, best=6)
plot(prune.data)
text(prune.data)

yhat = predict(prune.data, newdata=data[-data_train,])
sqrt(mean((yhat - data_test)^2))
```



